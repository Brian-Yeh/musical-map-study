{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re \n",
    "import numpy as np\n",
    "import json\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "song_files = ['2019-3-1','2019-3-15','2019-4-1','2019-4-15','2019-5-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_frequency(df):\n",
    "    pbar = tqdm_notebook(total=len(df))\n",
    "    entities_list = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        doc = nlp(row['lyrics'])\n",
    "        entities = [e.text for e in doc.ents \n",
    "                    if e.label_ not in ['LOC', 'MONEY', 'QUANTITY', 'ORDINAL', 'CARDINAL', 'DATE', 'TIME']]\n",
    "        entities_list.extend(entities)\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    return FreqDist(entities_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency(df):\n",
    "    pbar = tqdm_notebook(total=len(df))\n",
    "    tokens_list = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        tokens = nlp(row['lyrics'].lower())\n",
    "        tokens = [t.lemma_ for t in tokens if not t.is_stop and not t.is_punct]\n",
    "        tokens_list.extend(tokens)\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    return FreqDist(tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_info = pd.read_csv('../data/lyrics/song_info.txt')\n",
    "song_info = song_info[song_info['lang'] == 'en']\n",
    "reg = \"[\\(\\[].*?[\\)\\]]\"\n",
    "song_info['lyrics'] = song_info['lyrics'].replace(reg, '', regex=True)\n",
    "song_info['lyrics'] = song_info['lyrics'].str.replace('\\r', ' ').str.replace('\\n', ' ').str.replace('\\t', ' ')\n",
    "song_info['lyrics'] = song_info['lyrics'].str.replace(r\"\\s\\s+\", ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>song_id</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>São Paulo BR</td>\n",
       "      <td>6QOjOvLDWKVNCW9H1J9vCY</td>\n",
       "      <td>Leschea</td>\n",
       "      <td>Fulton St.</td>\n",
       "      <td>3xIHePHJbOEtnzlwAOoCtz</td>\n",
       "      <td>He be rollin' in his jeep Cruisin' down on Ful...</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Osasco BR</td>\n",
       "      <td>1rfYB95mbIDLnWOJCVr1AP</td>\n",
       "      <td>Leschea</td>\n",
       "      <td>Fulton St.</td>\n",
       "      <td>3xIHePHJbOEtnzlwAOoCtz</td>\n",
       "      <td>He be rollin' in his jeep Cruisin' down on Ful...</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los Angeles California US</td>\n",
       "      <td>53JqQphsAHvDGGVZErKmW5</td>\n",
       "      <td>Suga Free</td>\n",
       "      <td>Why U Bullshittin'?</td>\n",
       "      <td>3zb1zBmkrPF6VW8RhlSYA1</td>\n",
       "      <td>So pay attention, babe Pay attention Our Fathe...</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Las Vegas Nevada US</td>\n",
       "      <td>16olvYpf0K5nWJ98Oxa4TG</td>\n",
       "      <td>Suga Free</td>\n",
       "      <td>Why U Bullshittin'?</td>\n",
       "      <td>3zb1zBmkrPF6VW8RhlSYA1</td>\n",
       "      <td>So pay attention, babe Pay attention Our Fathe...</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corona California US</td>\n",
       "      <td>1lgTx3EbMGfQZ38U3EUjCk</td>\n",
       "      <td>Suga Free</td>\n",
       "      <td>Why U Bullshittin'?</td>\n",
       "      <td>3zb1zBmkrPF6VW8RhlSYA1</td>\n",
       "      <td>So pay attention, babe Pay attention Our Fathe...</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    location             playlist_id     artist  \\\n",
       "0               São Paulo BR  6QOjOvLDWKVNCW9H1J9vCY    Leschea   \n",
       "1                  Osasco BR  1rfYB95mbIDLnWOJCVr1AP    Leschea   \n",
       "2  Los Angeles California US  53JqQphsAHvDGGVZErKmW5  Suga Free   \n",
       "3        Las Vegas Nevada US  16olvYpf0K5nWJ98Oxa4TG  Suga Free   \n",
       "4       Corona California US  1lgTx3EbMGfQZ38U3EUjCk  Suga Free   \n",
       "\n",
       "                 title                 song_id  \\\n",
       "0           Fulton St.  3xIHePHJbOEtnzlwAOoCtz   \n",
       "1           Fulton St.  3xIHePHJbOEtnzlwAOoCtz   \n",
       "2  Why U Bullshittin'?  3zb1zBmkrPF6VW8RhlSYA1   \n",
       "3  Why U Bullshittin'?  3zb1zBmkrPF6VW8RhlSYA1   \n",
       "4  Why U Bullshittin'?  3zb1zBmkrPF6VW8RhlSYA1   \n",
       "\n",
       "                                              lyrics country  \n",
       "0  He be rollin' in his jeep Cruisin' down on Ful...      BR  \n",
       "1  He be rollin' in his jeep Cruisin' down on Ful...      BR  \n",
       "2  So pay attention, babe Pay attention Our Fathe...      US  \n",
       "3  So pay attention, babe Pay attention Our Fathe...      US  \n",
       "4  So pay attention, babe Pay attention Our Fathe...      US  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_3_17 = songs.merge(right=song_info[['song_id', 'lyrics']], how='inner', on='song_id')\n",
    "songs_3_17['country'] = songs_3_17.location.str[-2:]\n",
    "songs_3_17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>song_id</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>country</th>\n",
       "      <th>vader_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>São Paulo BR</td>\n",
       "      <td>6QOjOvLDWKVNCW9H1J9vCY</td>\n",
       "      <td>Leschea</td>\n",
       "      <td>Fulton St.</td>\n",
       "      <td>3xIHePHJbOEtnzlwAOoCtz</td>\n",
       "      <td>He be rollin' in his jeep Cruisin' down on Ful...</td>\n",
       "      <td>BR</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Osasco BR</td>\n",
       "      <td>1rfYB95mbIDLnWOJCVr1AP</td>\n",
       "      <td>Leschea</td>\n",
       "      <td>Fulton St.</td>\n",
       "      <td>3xIHePHJbOEtnzlwAOoCtz</td>\n",
       "      <td>He be rollin' in his jeep Cruisin' down on Ful...</td>\n",
       "      <td>BR</td>\n",
       "      <td>0.220677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los Angeles California US</td>\n",
       "      <td>53JqQphsAHvDGGVZErKmW5</td>\n",
       "      <td>Suga Free</td>\n",
       "      <td>Why U Bullshittin'?</td>\n",
       "      <td>3zb1zBmkrPF6VW8RhlSYA1</td>\n",
       "      <td>So pay attention, babe Pay attention Our Fathe...</td>\n",
       "      <td>US</td>\n",
       "      <td>-0.015660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Las Vegas Nevada US</td>\n",
       "      <td>16olvYpf0K5nWJ98Oxa4TG</td>\n",
       "      <td>Suga Free</td>\n",
       "      <td>Why U Bullshittin'?</td>\n",
       "      <td>3zb1zBmkrPF6VW8RhlSYA1</td>\n",
       "      <td>So pay attention, babe Pay attention Our Fathe...</td>\n",
       "      <td>US</td>\n",
       "      <td>-0.015660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corona California US</td>\n",
       "      <td>1lgTx3EbMGfQZ38U3EUjCk</td>\n",
       "      <td>Suga Free</td>\n",
       "      <td>Why U Bullshittin'?</td>\n",
       "      <td>3zb1zBmkrPF6VW8RhlSYA1</td>\n",
       "      <td>So pay attention, babe Pay attention Our Fathe...</td>\n",
       "      <td>US</td>\n",
       "      <td>-0.015660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    location             playlist_id     artist  \\\n",
       "0               São Paulo BR  6QOjOvLDWKVNCW9H1J9vCY    Leschea   \n",
       "1                  Osasco BR  1rfYB95mbIDLnWOJCVr1AP    Leschea   \n",
       "2  Los Angeles California US  53JqQphsAHvDGGVZErKmW5  Suga Free   \n",
       "3        Las Vegas Nevada US  16olvYpf0K5nWJ98Oxa4TG  Suga Free   \n",
       "4       Corona California US  1lgTx3EbMGfQZ38U3EUjCk  Suga Free   \n",
       "\n",
       "                 title                 song_id  \\\n",
       "0           Fulton St.  3xIHePHJbOEtnzlwAOoCtz   \n",
       "1           Fulton St.  3xIHePHJbOEtnzlwAOoCtz   \n",
       "2  Why U Bullshittin'?  3zb1zBmkrPF6VW8RhlSYA1   \n",
       "3  Why U Bullshittin'?  3zb1zBmkrPF6VW8RhlSYA1   \n",
       "4  Why U Bullshittin'?  3zb1zBmkrPF6VW8RhlSYA1   \n",
       "\n",
       "                                              lyrics country  vader_score  \n",
       "0  He be rollin' in his jeep Cruisin' down on Ful...      BR     0.220677  \n",
       "1  He be rollin' in his jeep Cruisin' down on Ful...      BR     0.220677  \n",
       "2  So pay attention, babe Pay attention Our Fathe...      US    -0.015660  \n",
       "3  So pay attention, babe Pay attention Our Fathe...      US    -0.015660  \n",
       "4  So pay attention, babe Pay attention Our Fathe...      US    -0.015660  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_scores = pd.read_csv('../data/vader_scores.txt')\n",
    "songs_3_17 = songs_3_17.merge(right=vader_scores, how='inner', on='song_id')\n",
    "songs_3_17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Somewhere', 'Drank', 'Drank', 'Drank', 'Drank', 'Drank']\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(0, len(song_info))\n",
    "doc = nlp(song_info.iloc[i]['lyrics'])\n",
    "ents = [(e.text) for e in doc.ents if e.label_ not in ['LOC', 'MONEY', 'QUANTITY', 'PERSON', 'ORDINAL', 'CARDINAL', 'DATE', 'TIME']]\n",
    "print(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431b2d8fb13d428a9336fdc4c657ee36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=446), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bitch', 18), ('Baby', 17), ('Keep', 13), ('Ooh', 12), ('Neighborhood', 10), ('Fuck', 9), ('Cause', 9), ('Sam', 8), ('Nellis', 8), ('Never', 6), ('Sittin', 6), ('Niggas', 6), ('Girl', 6), ('Down', 6), ('Angel', 5), ('Young', 5), ('Damn', 5), ('Candy', 5), ('Nigga', 5), ('Boulder Highway', 5), ('Pour', 5), ('Catch', 4), ('Makin', 4), ('Toot', 4), ('Step', 4), ('Yuh', 4), ('Lil Rob', 4), ('Swear', 4), ('El Monte', 4), ('Imma', 4)]\n"
     ]
    }
   ],
   "source": [
    "fdist = entity_frequency(df)\n",
    "most_common = fdist.most_common(30)\n",
    "print(most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_file = '../data/songs/songs_2019-5-2.txt'\n",
    "songs = pd.read_csv(songs_file)\n",
    "\n",
    "songs = songs.merge(right=song_info[['song_id', 'lyrics']], how='inner', on='song_id')\n",
    "songs['country'] = songs.location.str[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = songs[songs['location'] == 'Las Vegas Nevada US'].copy()\n",
    "# df = songs_3_17[songs_3_17['country'] == 'FR'].copy()\n",
    "df['song_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7141bee0174e79baf444820eaf93d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=65), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Keep', 25), ('Baby', 21), ('’m', 18), ('Ooh', 15), ('Pistol', 15), ('Duke', 15), ('Niggas', 13), ('Nigga', 10), ('Suavecito', 10), ('Fuck', 9), ('Girl', 9), ('Bitch', 8), ('Sam', 8), ('Nellis', 8), ('Cauz', 8), ('Ridin', 7), ('Damn', 7), ('Down', 7), ('Ac', 6), ('Chuckin', 6), ('Sittin', 6), ('Cause', 6), ('Earl Duke', 6), ('Angel', 5), ('Never', 5), ('Candy', 5), ('Boulder Highway', 5), ('Ese', 5), ('Young', 5), ('Matter', 4)]\n"
     ]
    }
   ],
   "source": [
    "fdist = entity_frequency(df)\n",
    "most_common = fdist.most_common(30)\n",
    "print(most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common Words:  Murfressboro Tennessee US vs. NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1da6edcfd82418f83bebb6fd88bdbc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=88), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location: Murfreesboro Tennessee US , Date: 2019-3-1\n",
      "[('like', 186), ('know', 160), ('love', 141), ('go', 139), ('get', 136), ('oh', 119), ('yeah', 102), ('want', 93), ('come', 88), ('life', 85), ('old', 79), ('time', 78), ('be', 77), ('night', 74), ('let', 73), ('long', 72), ('hope', 70), ('to', 68), ('bitch', 66), ('right', 65)]\n"
     ]
    }
   ],
   "source": [
    "location = 'Murfreesboro Tennessee US'\n",
    "songs_date = song_files[0]\n",
    "songs_file_path = '../data/songs/songs_'+songs_date+'.txt'\n",
    "songs = pd.read_csv(songs_file_path)\n",
    "\n",
    "songs = songs.merge(right=song_info[['song_id', 'lyrics']], how='inner', on='song_id')\n",
    "df = songs[songs['location'] == location].copy()\n",
    "fdist = word_frequency(df)\n",
    "most_common = fdist.most_common(20)\n",
    "print('Location:', location, ', Date:', songs_date)\n",
    "print(most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e903a0a08af4ada91ca3410cd198842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location: New York New York US , Date: 2019-3-1\n",
      "[('oh', 133), ('know', 90), ('get', 72), ('love', 66), ('yeah', 62), ('think', 59), ('like', 57), ('to', 56), ('go', 55), ('wanna', 54), ('time', 54), ('baby', 53), ('da', 52), ('tell', 43), ('world', 40), ('be', 37), ('look', 36), ('believe', 36), ('good', 36), ('new', 36)]\n"
     ]
    }
   ],
   "source": [
    "location = 'New York New York US'\n",
    "songs_date = song_files[0]\n",
    "songs_file_path = '../data/songs/songs_'+songs_date+'.txt'\n",
    "songs = pd.read_csv(songs_file_path)\n",
    "\n",
    "songs = songs.merge(right=song_info[['song_id', 'lyrics']], how='inner', on='song_id')\n",
    "df = songs[songs['location'] == location].copy()\n",
    "fdist = word_frequency(df)\n",
    "most_common = fdist.most_common(20)\n",
    "print('Location:', location, ', Date:', songs_date)\n",
    "print(most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entities: Murfressboro Tennessee vs. NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70fb3223f8145a588795a08c451a9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=88), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location: Murfreesboro Tennessee US , Date: 2019-3-1\n",
      "[('Jesus', 29), ('Morocco', 13), ('Bubba', 12), ('Tennessee', 11), ('Hank', 10), ('Baby', 7), ('David Ashley Parker', 7), ('Son', 7), ('Rocky Top', 6), ('Bae', 6), ('Said', 6), ('Love', 6), ('Louisiana', 6), ('Bitch', 4), ('USA', 4), ('Free', 4), ('Powder Springs', 4), ('Kick', 4), ('Daniel', 4), ('Moses', 4)]\n"
     ]
    }
   ],
   "source": [
    "location = 'Murfreesboro Tennessee US'\n",
    "songs_date = song_files[0]\n",
    "songs_file_path = '../data/songs/songs_'+songs_date+'.txt'\n",
    "songs = pd.read_csv(songs_file_path)\n",
    "\n",
    "songs = songs.merge(right=song_info[['song_id', 'lyrics']], how='inner', on='song_id')\n",
    "df = songs[songs['location'] == location].copy()\n",
    "fdist = entity_frequency(df)\n",
    "most_common = fdist.most_common(20)\n",
    "print('Location:', location, ', Date:', songs_date)\n",
    "print(most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc6fb860f59409baa068cdd1862e012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location: New York New York US , Date: 2019-3-1\n",
      "[('Cupid', 13), ('Time', 5), ('Broadway', 4), ('Comin', 4), ('Eating', 4), ('Circle', 3), ('Bentley', 3), ('Walkin', 3), ('Baby', 3), (\"Nothin'\", 3), ('Lalala', 2), ('Lambo', 2), ('Harlem', 2), ('Ooo', 2), ('Friendly', 2), ('Darlin', 2), ('Vegas', 1), ('PAMELA', 1), ('Divinest Pamela', 1), ('Lying by the sycamore', 1)]\n"
     ]
    }
   ],
   "source": [
    "location = 'New York New York US'\n",
    "songs_date = song_files[0]\n",
    "songs_file_path = '../data/songs/songs_'+songs_date+'.txt'\n",
    "songs = pd.read_csv(songs_file_path)\n",
    "\n",
    "songs = songs.merge(right=song_info[['song_id', 'lyrics']], how='inner', on='song_id')\n",
    "df = songs[songs['location'] == location].copy()\n",
    "fdist = entity_frequency(df)\n",
    "most_common = fdist.most_common(20)\n",
    "print('Location:', location, ', Date:', songs_date)\n",
    "print(most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
