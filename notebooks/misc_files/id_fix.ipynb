{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spotify Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_file = '../keys.json'\n",
    "with open(key_file) as f:\n",
    "    keys = json.load(f)\n",
    "    \n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=keys['spotify_client_id'],\n",
    "                                                      client_secret=keys['spotify_client_secret'])\n",
    "spotify = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_markets = [\"AD\",\"AR\",\"AT\",\"AU\",\"BE\",\"BG\",\"BO\",\"BR\",\"CA\",\"CH\",\"CL\",\"CO\",\"CR\",\"CY\",\"CZ\",\n",
    "      \"DE\",\"DK\",\"DO\",\"EC\",\"EE\",\"ES\",\"FI\",\"FR\",\"GB\",\"GR\",\"GT\",\"HK\",\"HN\",\"HU\",\"ID\",\"IE\",\"IL\",\"IS\",\n",
    "      \"IT\",\"JP\",\"LI\",\"LT\",\"LU\",\"LV\",\"MC\",\"MT\",\"MX\",\"MY\",\"NI\",\"NL\",\"NO\",\"NZ\",\"PA\",\"PE\",\"PH\",\"PL\",\n",
    "      \"PT\",\"PY\",\"RO\",\"SE\",\"SG\",\"SK\",\"SV\",\"TH\",\"TR\",\"TW\",\"US\",\"UY\",\"VN\",\"ZA\"]\n",
    "\n",
    "\n",
    "def fix_ids(row):\n",
    "    time.sleep(.01)\n",
    "    if row['location'][-2:] in available_markets:\n",
    "        try:\n",
    "            query = spotify.search(q=row['artist'] + ' ' + row['title'], market=row['location'][-2:], type='track')\n",
    "            for item in query['tracks']['items']:\n",
    "                if item['id'][1:] == row['song_id']:\n",
    "                    return item['id']\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    query = spotify.search(q=row['artist'] + ' ' + row['title'], market='US', type='track')\n",
    "    for item in query['tracks']['items']:\n",
    "            if item['id'][1:] == row['song_id']:\n",
    "                return item['id']\n",
    "            \n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def fix_ids_brute(row):\n",
    "    time.sleep(.5)\n",
    "    for c in '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ':\n",
    "        try:\n",
    "            result = spotify.track(c+row['song_id'])\n",
    "            return result['id']\n",
    "        except:\n",
    "            pass\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate IDs that need fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'songs_2019-3-1_11-31-2.txt'\n",
    "file_path = '../data/songs/bad_ids/'+file_name\n",
    "output_file_path = '../data/songs/'+file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv(file_path)\n",
    "id_map = pd.read_csv('../data/id_map.txt')\n",
    "songs_fix = songs.merge(right=id_map, how='left', on='song_id')\n",
    "songs_fix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(songs_fix))\n",
    "\n",
    "id_needed = songs_fix[songs_fix['id_fix'].isnull()].copy()\n",
    "print(len(id_needed))\n",
    "id_needed.drop_duplicates(subset=['song_id'], inplace=True)\n",
    "print(len(id_needed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use one of two methods to regenerate Spotify ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_needed['id_fix'] = id_needed.progress_apply(lambda row:fix_ids(row), axis=1)\n",
    "# id_needed['id_fix'] = id_needed.progress_apply(lambda row:fix_ids_brute(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(id_needed))\n",
    "id_needed.to_csv(path_or_buf='../data/id_needed.txt', index=False, encoding='utf-8')\n",
    "still_missing = id_needed[id_needed['id_fix'].isnull()].copy()\n",
    "print(len(still_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_needed.dropna(inplace=True, subset=['id_fix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = pd.read_csv('data/id_map.txt')\n",
    "print(len(id_map))\n",
    "id_map = id_map.append(id_needed[['song_id', 'id_fix']], ignore_index=True)\n",
    "print(len(id_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map.drop_duplicates(subset=['id_fix'], inplace=True)\n",
    "id_map.dropna(subset=['id_fix'], inplace=True)\n",
    "print(len(id_map))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map.to_csv(path_or_buf='./data/id_map.txt', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge fixed IDs from new ID Map into the songs file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv(file_path)\n",
    "id_map = pd.read_csv('../data/id_map.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = songs.merge(right=id_map, how='left', on='song_id')\n",
    "assert(len(songs[songs['id_fix'].isnull()]) == 0)\n",
    "songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.drop(columns=['song_id'], inplace=True)\n",
    "songs.rename(columns={'id_fix': 'song_id'}, inplace=True)\n",
    "songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Bad IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = '../data/bad_ids/lyrics_with_lang.txt'\n",
    "output_file_path = '../data/lyrics_with_lang.txt'\n",
    "\n",
    "bad_ids = pd.read_csv(input_file_path)\n",
    "id_map = pd.read_csv('../data/id_map.txt') \n",
    "len(id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed = bad_ids.merge(right=id_map, how='left', on='song_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed.drop(columns=['song_id'], inplace=True)\n",
    "fixed.rename(columns={'id_fix': 'song_id'}, inplace=True)\n",
    "fixed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fixed))\n",
    "fixed.dropna(subset=['song_id'], inplace=True)\n",
    "print(len(fixed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed.to_csv(path_or_buf=output_file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ids = pd.read_csv('../data/songs/bad_ids/songs_2019-3-17_12-31-9.txt')\n",
    "bad_ids.drop_duplicates(subset=['song_id'], inplace=True)\n",
    "id_map = pd.read_csv('../data/id_map.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = bad_ids.merge(id_map, how='left', on='song_id')\n",
    "missing = missing[missing['id_fix'].isnull()].copy()\n",
    "len(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use brute method to find IDs that are still missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "still_missing = missing[missing['id_fix'].isnull()].copy()\n",
    "still_missing['id_fix'] = still_missing.progress_apply(lambda row:fix_ids_brute(row), axis=1)\n",
    "still_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "still_missing.to_csv('still_missing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id_map = id_map.append(still_missing[['song_id', 'id_fix']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_id_map.to_csv(path_or_buf='../data/id_map.txt', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
